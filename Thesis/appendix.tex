% =========================================================
% APPENDIX A: Laplacian conditioning
% =========================================================
\chapter{Laplacian conditioning}
\label{app:laplacian}

\section{Residual training for Schr\"odinger}
\label{app:laplacian:setup}

We consider the stationary many-body Schr\"odinger equation on configuration space
$\mathbf R=(\mathbf r_1,\ldots,\mathbf r_N)\in\Omega\subset\mathbb R^{D}$ with $D=dN$
(for our quantum dots, $d=2$):
\begin{equation}
\hat H\Psi(\mathbf R)=E\Psi(\mathbf R),
\qquad
\hat H=\hat T+\hat V,
\qquad
\hat T=-\frac12\sum_{i=1}^N\Delta_i,
\label{eq:lap:sch}
\end{equation}
where $\hat V$ collects external and interaction potentials.

In \emph{strong residual minimization} one introduces
\begin{equation}
L := \hat H - E \quad\Rightarrow\quad L\Psi = 0,
\end{equation}
and minimizes a squared residual loss of the schematic form
\begin{equation}
\mathcal L_{\mathrm{res}}(\theta)
= \frac12\|L\Psi_\theta\|_{L^2(\Omega;w)}^2
= \frac12\int_\Omega |(L\Psi_\theta)(\mathbf R)|^2\,w(\mathbf R)\,d\mathbf R,
\label{eq:lap:resloss}
\end{equation}
for a nonnegative weight $w$ induced by the sampling strategy.
A key message of the numerical-analysis viewpoint is that strong residual losses
can be \emph{severely ill-conditioned}, and training speed is tightly linked to
spectral properties of an operator/matrix induced by $L$ \cite{De_Ryck_2024}.

\section{Linearized geometry and the matrix \(A\)}
\label{app:laplacian:A}

To expose the mechanism, follow the standard linearization argument used in
conditioning analyses \cite{De_Ryck_2024}.
Fix an expansion point $\theta_0$ and define tangent (feature) functions
\begin{equation}
q_j(\mathbf R) := \partial_{\theta_j}\Psi_\theta(\mathbf R)\big|_{\theta=\theta_0},
\qquad j=1,\ldots,P.
\end{equation}
For small parameter increments $\delta\theta$, we have the first-order model
\begin{equation}
\Psi_{\theta_0+\delta\theta}(\mathbf R)
\approx
\Psi_0(\mathbf R)+\sum_{j=1}^P q_j(\mathbf R)\,\delta\theta_j,
\qquad
\Psi_0:=\Psi_{\theta_0}.
\label{eq:lap:linPsi}
\end{equation}
Applying the residual operator gives
\begin{equation}
(L\Psi_{\theta_0+\delta\theta})(\mathbf R)
\approx
(L\Psi_0)(\mathbf R)+\sum_{j=1}^P (Lq_j)(\mathbf R)\,\delta\theta_j.
\label{eq:lap:linRes}
\end{equation}

Introduce the weighted inner product (complex-valued wavefunctions allowed)
\begin{equation}
\langle f,g\rangle_w := \int_\Omega f(\mathbf R)^\ast\,g(\mathbf R)\,w(\mathbf R)\,d\mathbf R.
\end{equation}
Let the Jacobian $J$ be the linear map whose $j$th column is $Lq_j$.
Then the loss \eqref{eq:lap:resloss} becomes (to second order in $\delta\theta$)
\begin{equation}
\mathcal L_{\mathrm{res}}(\theta_0+\delta\theta)
\approx
\frac12\|r_0 + J\,\delta\theta\|_w^2,
\qquad
r_0 := L\Psi_0.
\label{eq:lap:lsq}
\end{equation}
with normal-equation matrix
\begin{equation}
A := J^\ast J,
\qquad
A_{ij}=\langle Lq_i,\,Lq_j\rangle_w.
\label{eq:lap:Adef}
\end{equation}
Here $A$ is Hermitian positive semidefinite; in practice it can be close to singular,
so one often effectively works with a damped variant $A+\lambda I$ (implicit or explicit).

Now consider gradient descent on the quadratic model \eqref{eq:lap:lsq}
(with step size $\eta$). The error in parameter space evolves as
\begin{equation}
\delta\theta^{(t+1)}-\delta\theta^\star
=
\left(I-\eta A\right)\left(\delta\theta^{(t)}-\delta\theta^\star\right),
\label{eq:lap:GD}
\end{equation}
so each eigen-direction of $A$ contracts by a factor $(1-\eta\lambda)$.
Hence convergence speed is governed by the eigenvalue spread of $A$,
typically summarized by the (effective) condition number
\begin{equation}
\kappa(A)=\frac{\lambda_{\max}(A)}{\lambda_{\min}(A)}
\end{equation}
(over the nonzero/regularized spectrum).
Large $\kappa(A)$ implies stiffness: a step size small enough to be stable for
$\lambda_{\max}$ yields slow progress along directions associated with
$\lambda_{\min}$. This is precisely the conditioning bottleneck emphasized in
physics-informed training analyses \cite{De_Ryck_2024}.

\section{Bi-Laplacian scaling}
\label{app:laplacian:bilap}

The defining feature of Schr\"odinger is that $L$ contains a second-order
differential operator. To isolate the kinetic contribution, consider the regime
where the residual is dominated by the Laplacian part,
\begin{equation}
L \approx -\frac12\Delta_{\mathbf R}.
\label{eq:lap:Lapprox}
\end{equation}

\paragraph{From \(L\) to \(L^\ast L\).}
The matrix $A$ in \eqref{eq:lap:Adef} is a Gram matrix in the feature space
$\{Lq_j\}$.
The corresponding operator-level object is the \emph{Hermitian square}
$L^\ast L$ (with adjoint taken in the $L^2(\Omega;w)$ inner product)
\cite{De_Ryck_2024}. For general non-constant $w$, the adjoint $L^\ast$ differs from the
formal differential adjoint by weight-induced lower-order terms; the cleanest picture
is obtained for constant $w$ and standard boundary conditions (periodic/Dirichlet),
where the Laplacian is self-adjoint.

In the Laplacian-dominant regime \eqref{eq:lap:Lapprox}, one has (up to a constant factor)
\begin{equation}
L \approx -\tfrac12\Delta
\quad\Rightarrow\quad
L^\ast L \approx \tfrac14\,\Delta^2,
\label{eq:lap:bilap}
\end{equation}
i.e.\ a bi-Laplacian scaling. The prefactor does not affect conditioning ratios.

\paragraph{Fourier/eigenmode derivation of \(k^4\).}
On a periodic domain (or, more generally, in a Laplacian eigenbasis)
\(
-\Delta \phi_{\mathbf k} = |\mathbf k|^2\phi_{\mathbf k},
\)
so
\(
\Delta^2\phi_{\mathbf k} = |\mathbf k|^4\phi_{\mathbf k}.
\)
If an error $\delta\Psi$ expands as $\delta\Psi=\sum_{\mathbf k}c_{\mathbf k}\phi_{\mathbf k}$
and $L\approx -\tfrac12\Delta$, then
\begin{equation}
\|L\,\delta\Psi\|_{L^2}^2
\approx
\frac14\sum_{\mathbf k} |\mathbf k|^4|c_{\mathbf k}|^2.
\label{eq:lap:k4}
\end{equation}
Thus the squared residual penalizes high-frequency components with a \emph{quartic}
weight $|\mathbf k|^4$.
If the relevant spectrum spans $|\mathbf k|\in[k_{\min},k_{\max}]$, the induced
eigenvalue ratio scales like
\begin{equation}
\kappa \sim \left(\frac{k_{\max}}{k_{\min}}\right)^4,
\label{eq:lap:kappa}
\end{equation}
which is a sharp mathematical expression of ``Laplacian-driven stiffness''.
This quartic growth is consistent with the Laplacian/Poisson toy examples and
frequency-dependent conditioning effects emphasized in \cite{De_Ryck_2024}.

\paragraph{Length-scale interpretation.}
Let $\ell$ denote the smallest length scale that must be represented.
Then $k_{\max}\sim 1/\ell$ and \eqref{eq:lap:kappa} implies
\begin{equation}
\kappa \ \text{grows rapidly as}\ \ell\downarrow 0.
\end{equation}
In many-body Schr\"odinger problems, small $\ell$ arises from nodal structure,
strong localization, and short-range correlation features; in all such regimes,
the Laplacian makes the strong residual extremely curvature-sensitive.

\section{Barron/spectral perspective}
\label{app:laplacian:barron}

The conditioning story above can be rephrased in approximation terms.
In spectral Barron-type viewpoints, function classes are controlled by norms that
weight the Fourier transform by powers of frequency (or related spectral weights).
A key implication is that applying derivatives systematically increases the
importance of high-frequency tails \cite{De_Ryck_2024}.
Since $\Delta$ multiplies a Fourier mode by $|\mathbf k|^2$, and the squared
residual effectively involves $L^\ast L$ (hence $\Delta^2$ in Laplacian-dominant
regimes), the residual can require substantially more ``spectral budget'' than
the wavefunction itself.
In practical terms: even if $\Psi$ is approximable in a given network class,
\emph{approximating its strong residual} can be much harder, because the loss
implicitly demands accurate high-frequency curvature (cf.\ \eqref{eq:lap:k4}).
This is one of the motivations, in numerical analysis of PINNs, for considering
weak/variational formulations that reduce derivative order when the strong form
is too stiff \cite{De_Ryck_2024}.

\section{Implications for Stochastic Reconfiguration}
\label{app:laplacian:sr}

Stochastic reconfiguration (SR) updates parameters using a natural-gradient-like
preconditioner \cite{BeccaSorella2017-QMCBook,Amari1998-NaturalGradient,ParkKastoryano2020-GeometryNQS}.
Writing $O_i=\partial_{\theta_i}\log\Psi_\theta$, one common SR update is
\begin{equation}
S(\theta)\,\delta\theta = -g(\theta),
\qquad
S_{ij}=\mathrm{Cov}_{p_\theta}[O_i,O_j],
\qquad
g_i=\mathrm{Cov}_{p_\theta}[E_L,O_i],
\label{eq:lap:sr}
\end{equation}
where $p_\theta\propto|\Psi_\theta|^2$ and $E_L=(\hat H\Psi_\theta)/\Psi_\theta$.
SR improves conditioning in parameter space by using the (quantum) information
geometry of the variational family \cite{Amari1998-NaturalGradient,ParkKastoryano2020-GeometryNQS}.
However, the Laplacian-induced stiffness described above is an \emph{operator-level}
phenomenon: strong residuals magnify curvature errors via $\Delta$ and $\Delta^2$
(cf.\ \eqref{eq:lap:k4}), which remains a fundamental challenge even when parameter
updates are geometrically preconditioned.



% =========================================================
% APPENDIX B: Coulomb conditioning (2D, spin channels)
% =========================================================
\chapter{Coulomb conditioning}
\label{app:coulomb}

\section{Coulomb structure and singularity}
\label{app:coulomb:setup}

For our two-dimensional electronic systems ($\mathbf r_i\in\mathbb R^2$), the interaction
contains Coulomb terms of the form
\begin{equation}
\hat V_{\mathrm C}(\mathbf R)=\sum_{1\le i<j\le N}\frac{1}{r_{ij}},
\qquad r_{ij}=|\mathbf r_i-\mathbf r_j|.
\label{eq:coulomb:V}
\end{equation}
This is a \emph{singular multiplication operator}: it diverges at particle
coalescence $r_{ij}\to 0$.
The exact eigenfunction remains finite (or vanishes by antisymmetry) but develops
non-smooth short-distance structure (a cusp) so that divergences in kinetic and
potential contributions cancel in physically meaningful quantities such as the
local energy \cite{BeccaSorella2017-QMCBook}.

The central point for learning is:

\begin{quote}
Coulomb does not merely add ``another term'' to the residual; it introduces
\emph{singular short-range physics} that forces delicate cancellations with the
Laplacian. Strong residual objectives square these effects and become extremely
sensitive to tiny cusp errors.
\end{quote}

\section{2D cusp conditions: antiparallel vs parallel spins}
\label{app:coulomb:cusp}

We present the 2D cusp logic in a way that separates the two spin channels.
The cleanest statement (especially for practical ans\"atze) is in terms of the
short-distance behavior of a \emph{Slater--Jastrow} factorization
\begin{equation}
\Psi(\mathbf R)=D(\mathbf R)\,J(\mathbf R),
\qquad
J(\mathbf R)=\exp\!\Big(\sum_{i<j} u(r_{ij})\Big),
\label{eq:coulomb:slater-jastrow}
\end{equation}
because (i) the Slater part $D$ enforces antisymmetry and determines whether $\Psi$
vanishes at coalescence, and (ii) the Jastrow slope $u'(0)$ is what cancels the
$1/r$ Coulomb singularity in the local energy \cite{BeccaSorella2017-QMCBook}.

Fix a pair $(i,j)$ and introduce relative/center-of-mass coordinates in 2D:
\begin{equation}
\mathbf R_{ij} := \frac{\mathbf r_i+\mathbf r_j}{2},
\qquad
\mathbf r := \mathbf r_i-\mathbf r_j,
\qquad
r:=|\mathbf r|.
\end{equation}
A direct computation gives, in any dimension,
\begin{equation}
\Delta_i+\Delta_j = \frac12\,\Delta_{\mathbf R_{ij}} + 2\,\Delta_{\mathbf r},
\label{eq:coulomb:lap_decomp}
\end{equation}
hence the singular short-distance kinetic behavior is controlled by the relative term
$-\Delta_{\mathbf r}$.

A key 2D identity is
\begin{equation}
\Delta_{\mathbf r} r = \frac{1}{r}\qquad (r>0,\ \mathbf r\in\mathbb R^2).
\label{eq:coulomb:lap_r_2d}
\end{equation}

\paragraph{Antiparallel spins (distinguishable in the Slater part).}
If the two electrons have opposite spin, they enter different determinants in $D$
and generically $D$ does \emph{not} vanish at $\mathbf r\to 0$. Then $\Psi(0)\neq 0$ and
a direct cusp expansion in 2D is legitimate:
\begin{equation}
\Psi(\mathbf r,\ldots)
=
\Psi(0,\ldots)\Big(1 + a\,r + \mathcal O(r^2)\Big),
\qquad r\to 0.
\label{eq:coulomb:expansion_anti}
\end{equation}
Using \eqref{eq:coulomb:lap_r_2d}, the singular part of the relative Laplacian is
\begin{equation}
\Delta_{\mathbf r}\Psi \approx \Psi(0)\,a\,\Delta_{\mathbf r}r
= \Psi(0)\,\frac{a}{r},
\qquad
\frac{\Delta_{\mathbf r}\Psi}{\Psi}\approx \frac{a}{r}.
\label{eq:coulomb:lap_sing_2d}
\end{equation}
Since the pair kinetic contribution contains $-\Delta_{\mathbf r}$, the singular part
of the local energy is
\begin{equation}
E_L(\mathbf R)=\frac{\hat H\Psi}{\Psi}\supset \left(-\frac{a}{r}+\frac{1}{r}\right)
=\frac{1-a}{r}.
\label{eq:coulomb:EL_sing_2d_anti}
\end{equation}
Thus finiteness of $E_L$ at coalescence requires
\begin{equation}
a=1,
\qquad\text{i.e.}\qquad
\left.\partial_r \log \Psi\right|_{r=0}=1
\quad\text{(2D, antiparallel spins)}.
\label{eq:coulomb:cusp_2d_anti}
\end{equation}
Equivalently, in a Slater--Jastrow form with $D(0)\neq 0$,
this is the same as $\partial_r\log J|_{0}=1$ for the $ij$-pair.

\paragraph{Parallel spins (identical fermions, node at coalescence).}
For same-spin electrons, antisymmetry forces $D$ (and hence $\Psi$) to vanish as
$\mathbf r\to 0$. Generically one has a \emph{linear} zero:
\begin{equation}
D(\mathbf r,\ldots) \;=\; \bm\eta(\ldots)\cdot \mathbf r \;+\; \mathcal O(r^2),
\qquad r\to 0,
\label{eq:coulomb:D_linear_zero}
\end{equation}
with some nonzero vector $\bm\eta$ depending on the other coordinates.
In this case, the cancellation of the Coulomb singularity is controlled by the
Jastrow factor through cross terms in $-\Delta_{\mathbf r}(DJ)/(DJ)$.
A standard short-distance analysis (carried out explicitly for 2D quantum dots)
shows that the divergent kinetic contribution behaves like
\begin{equation}
-\frac{\Delta_{\mathbf r}(DJ)}{DJ}
\supset
-\frac{(2k+d-1)}{r}\,\partial_r\log J
\qquad\text{with}\qquad
d=2,\ \ k=1\ \text{(identical particles)},
\label{eq:coulomb:jastrow_div}
\end{equation}
while the Coulomb potential contributes $+1/r$ to $E_L$ as before.
Hence finiteness of the local energy requires
\begin{equation}
\left.\partial_r\log J\right|_{r=0}=\frac{1}{2k+d-1}=\frac{1}{3}
\quad\text{(2D, parallel spins)}.
\label{eq:coulomb:cusp_2d_par}
\end{equation}
This $1$ (antiparallel) versus $1/3$ (parallel) 2D cusp statement is the
standard quantum-dot/Jastrow--Slater cusp condition \cite{Siljamaki2003-QD-Cusps}.

\paragraph{What to remember.}
In 2D:
\begin{align}
\text{antiparallel spins:}\quad & \left.\partial_r\log \Psi\right|_{0}=1
\;\;\;\Longleftrightarrow\;\;\;
\left.\partial_r\log J\right|_{0}=1,
\label{eq:coulomb:summary_anti}
\\
\text{parallel spins:}\quad & \Psi(0)=0\ \text{(linear node)},\ \ 
\left.\partial_r\log J\right|_{0}=\frac13.
\label{eq:coulomb:summary_par}
\end{align}

\section{Why Coulomb is ill-conditioned (2D emphasis)}
\label{app:coulomb:residual}

The cusp conditions above show \emph{how} Coulomb creates stiffness: it forces
kinetic and potential contributions to be individually large and singular,
while their \emph{sum} is finite only under a short-distance constraint.
Strong residual minimization is therefore a \emph{cancellation problem}.

\paragraph{Sensitivity amplification in the local energy.}
If the learned antiparallel-spin cusp slope is $a_\theta = 1+\delta a$, then
\eqref{eq:coulomb:EL_sing_2d_anti} implies
\begin{equation}
E_L(\mathbf R)\supset -\frac{\delta a}{r},
\label{eq:coulomb:EL_mismatch_2d_anti}
\end{equation}
so an arbitrarily small cusp mismatch produces an arbitrarily large local-energy spike
as $r\to 0$.

For parallel spins, if the learned Jastrow slope is
$\partial_r\log J|_{0}=\frac13+\delta b$, then the same short-distance analysis leading to
\eqref{eq:coulomb:cusp_2d_par} implies
\begin{equation}
E_L(\mathbf R)\supset -\frac{3\,\delta b}{r}.
\label{eq:coulomb:EL_mismatch_2d_par}
\end{equation}
Thus both channels generate $1/r$ spikes unless the cusp is satisfied.

\paragraph{Why squaring is especially dangerous in 2D.}
A $1/r$ defect in $E_L$ (or in $(\hat H-E)\Psi$) is concentrated near coalescence.
But in 2D the squared singularity is only \emph{log-integrable}:
\[
\int_{r<\varepsilon}\Big(\frac{1}{r}\Big)^2\, d^2\mathbf r
=
\int_0^\varepsilon \frac{1}{r^2}\,(2\pi r\,dr)
=
2\pi\int_0^\varepsilon \frac{dr}{r}
=+\infty.
\]
Therefore, without effectively resolving the cusp, \emph{strong} squared-residual
objectives can be dominated (or even made ill-defined in the continuum limit) by the
coalescence region. In Monte Carlo practice, this manifests as heavy-tailed fluctuations
and extreme sensitivity to rare close-pair samples.

\paragraph{Residual expansion and cancellation structure.}
Writing $L=\hat T+(\hat V-E)$ and expanding the squared residual norm:
\begin{equation}
\|L\Psi\|_w^2
=
\|\hat T\Psi\|_w^2 + \|(\hat V-E)\Psi\|_w^2
+2\,\Re\langle \hat T\Psi,\;(\hat V-E)\Psi\rangle_w,
\label{eq:coulomb:expand}
\end{equation}
we see that near coalescence both $\hat T\Psi$ and $\hat V_{\mathrm C}\Psi$ are large.
The exact solution relies on cancellation between these contributions
(cf.\ \eqref{eq:coulomb:EL_sing_2d_anti} and \eqref{eq:coulomb:cusp_2d_par}), which means
\eqref{eq:coulomb:expand} demands high \emph{relative} accuracy in the cusp region:
if either term is off by a small fraction, the net residual can be large in absolute magnitude.
This is a classic recipe for ill-conditioning: the loss landscape contains directions
where small parameter changes cause huge residual changes in a small region.

\paragraph{Operator-level picture (\(L^\ast L\)).}
From the same viewpoint as Appendix~\ref{app:laplacian}, strong residual training
induces matrices/operators tied to $L^\ast L$ \cite{De_Ryck_2024}.
For $L=\hat T+(\hat V-E)$, one has (formally)
\begin{equation}
L^\ast L
=
\hat T^2 + (\hat V-E)^2 + \hat T(\hat V-E) + (\hat V-E)\hat T.
\label{eq:coulomb:LstarL}
\end{equation}
Coulomb enters here in two destabilizing ways:
\begin{enumerate}
\item the positive term $(\hat V-E)^2$ involves a $1/r^2$-type singular weight;
\item the mixed terms contain derivatives of $V$ through product rules, e.g.
$\hat T(V\Psi)$ generates $\nabla V\cdot\nabla\Psi$ and $\Delta V$ contributions,
which are even more singular/distributional at coalescence.
\end{enumerate}
This formal expansion explains why the Coulomb singularity can severely inflate
the effective spectral spread of the training operator, aligning with the
operator-conditioning viewpoint \cite{De_Ryck_2024}.

\section{Barron/spectral perspective}
\label{app:coulomb:barron}

Coulomb forces the \emph{true} 2D solution to have cusp-like, non-smooth short-range
structure, so approximating the \emph{strong residual} requires representing
high-frequency content that is not well captured by globally smooth/low-complexity
function classes.

In spectral/Barron-style approximation theories, approximation quality is governed
by spectral decay and norms that weight the Fourier tail \cite{De_Ryck_2024}.
A cusp (or a linear node times a cusp in $J$) implies slower spectral decay than a globally
smooth function.
Strong residual training then \emph{further} amplifies the high-frequency tail
because it applies $\Delta$ (and effectively $L^\ast L$), which multiplies Fourier
modes by powers of $|\mathbf k|$ (Appendix~\ref{app:laplacian}).
Hence, even if $\Psi$ can be approximated reasonably in function value, the strong
residual can remain large unless the cusp structure is represented accurately.
This is exactly the type of regularity mismatch that motivates weak/variational
formulations in numerical analysis of PINN-type methods, since weak forms reduce
the derivative order demanded of the approximation \cite{De_Ryck_2024}.

Practically, QMC wavefunctions therefore incorporate explicit short-range
correlation structure (e.g.\ cusp-enforcing Jastrow factors), precisely to remove
these singular residual pathologies and reduce the variance of local quantities
\cite{BeccaSorella2017-QMCBook,Siljamaki2003-QD-Cusps}.

\section{Implications for Stochastic Reconfiguration}
\label{app:coulomb:sr}

SR performs a natural-gradient step using a (quantum) Fisher/metric matrix
\cite{BeccaSorella2017-QMCBook,Amari1998-NaturalGradient,ParkKastoryano2020-GeometryNQS}.
In one common formulation,
\begin{equation}
S_{ij}=\mathrm{Cov}_{p_\theta}[O_i,O_j],
\qquad
g_i=\mathrm{Cov}_{p_\theta}[E_L,O_i],
\qquad
S\,\delta\theta=-g,
\label{eq:coulomb:sr}
\end{equation}
with $O_i=\partial_{\theta_i}\log\Psi_\theta$.

Coulomb-induced cusp mismatch produces $E_L$ spikes of the form
\eqref{eq:coulomb:EL_mismatch_2d_anti}--\eqref{eq:coulomb:EL_mismatch_2d_par},
which has two consequences:
\begin{enumerate}
\item \textbf{Heavy-tailed Monte Carlo forces.}
The estimator of $g_i=\mathrm{Cov}[E_L,O_i]$ becomes noisy when $E_L$ has rare but
extreme spikes (short-range events). This increases variance and can destabilize
the linear solve unless one uses damping/regularization, as standard in SR practice
\cite{BeccaSorella2017-QMCBook}.
\item \textbf{Coupling to curvature sensitivity.}
Even if SR corrects anisotropy in parameter space (natural gradient)
\cite{Amari1998-NaturalGradient,ParkKastoryano2020-GeometryNQS}, it does not remove
the underlying operator-driven stiffness: the spikes originate from imperfect
kinetic--potential cancellation enforced by Coulomb cusp physics.
\end{enumerate}

\paragraph{Bottom line.}
Laplacian dominance creates stiffness through $k^4$-type amplification of curvature
errors; Coulomb creates stiffness by enforcing cusp constraints (in 2D: $1$ vs $1/3$
depending on spin channel) and cancellation against the Laplacian.
Both mechanisms worsen conditioning of strong residual objectives and increase
statistical difficulty of SR through heavy-tailed local-energy fluctuations
\cite{De_Ryck_2024,BeccaSorella2017-QMCBook,Siljamaki2003-QD-Cusps}.

% ---------------------------------------------------------
% Add this BibTeX entry (new) if you want the 2D 1 vs 1/3 cusp citation:
% ---------------------------------------------------------
% @phdthesis{Siljamaki2003-QD-Cusps,
%   author = {Sami Siljam{\"a}ki},
%   title  = {Wave Function Methods for Quantum Dots in Magnetic Field},
%   school = {Helsinki University of Technology},
%   year   = {2003},
%   note   = {See Sec.~2.4 (Cusp conditions), Eq.~(2.27) and the 2D specialization giving
%             $\partial_r J/J = C$ (antiparallel) and $\partial_r J/J = C/3$ (parallel).}
% }
